{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = 'data/train'\n",
    "test_data = 'data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = 28709\n",
    "num_test = 7178\n",
    "batch_size = 64\n",
    "num_epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_data_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_data_gen.flow_from_directory(\n",
    "    train_data, \n",
    "    target_size=(48,48),\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_data_gen.flow_from_directory(\n",
    "    test_data,\n",
    "    target_size=(48,48),\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.0001, decay=1e-6),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-30-68623e7c2077>:3: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 448 steps, validate for 112 steps\n",
      "Epoch 1/50\n",
      "448/448 [==============================] - 568s 1s/step - loss: 1.8042 - accuracy: 0.2564 - val_loss: 1.7295 - val_accuracy: 0.3270\n",
      "Epoch 2/50\n",
      "448/448 [==============================] - 264s 589ms/step - loss: 1.6371 - accuracy: 0.3639 - val_loss: 1.5477 - val_accuracy: 0.4116\n",
      "Epoch 3/50\n",
      "448/448 [==============================] - 243s 542ms/step - loss: 1.5332 - accuracy: 0.4082 - val_loss: 1.4631 - val_accuracy: 0.4404\n",
      "Epoch 4/50\n",
      "448/448 [==============================] - 223s 498ms/step - loss: 1.4607 - accuracy: 0.4389 - val_loss: 1.4017 - val_accuracy: 0.4632\n",
      "Epoch 5/50\n",
      "448/448 [==============================] - 245s 547ms/step - loss: 1.3990 - accuracy: 0.4669 - val_loss: 1.3493 - val_accuracy: 0.4847\n",
      "Epoch 6/50\n",
      "448/448 [==============================] - 218s 486ms/step - loss: 1.3490 - accuracy: 0.4890 - val_loss: 1.3053 - val_accuracy: 0.5049\n",
      "Epoch 7/50\n",
      "448/448 [==============================] - 217s 484ms/step - loss: 1.3031 - accuracy: 0.5080 - val_loss: 1.2705 - val_accuracy: 0.5225\n",
      "Epoch 8/50\n",
      "448/448 [==============================] - 217s 484ms/step - loss: 1.2581 - accuracy: 0.5257 - val_loss: 1.2564 - val_accuracy: 0.5176\n",
      "Epoch 9/50\n",
      "448/448 [==============================] - 219s 489ms/step - loss: 1.2249 - accuracy: 0.5372 - val_loss: 1.2282 - val_accuracy: 0.5296\n",
      "Epoch 10/50\n",
      "448/448 [==============================] - 218s 487ms/step - loss: 1.1968 - accuracy: 0.5528 - val_loss: 1.1952 - val_accuracy: 0.5472\n",
      "Epoch 11/50\n",
      "448/448 [==============================] - 218s 486ms/step - loss: 1.1688 - accuracy: 0.5631 - val_loss: 1.1793 - val_accuracy: 0.5515\n",
      "Epoch 12/50\n",
      "448/448 [==============================] - 217s 485ms/step - loss: 1.1422 - accuracy: 0.5727 - val_loss: 1.1596 - val_accuracy: 0.5568\n",
      "Epoch 13/50\n",
      "448/448 [==============================] - 218s 486ms/step - loss: 1.1186 - accuracy: 0.5834 - val_loss: 1.1695 - val_accuracy: 0.5551\n",
      "Epoch 14/50\n",
      "448/448 [==============================] - 219s 488ms/step - loss: 1.0901 - accuracy: 0.5931 - val_loss: 1.1408 - val_accuracy: 0.5657\n",
      "Epoch 15/50\n",
      "448/448 [==============================] - 217s 485ms/step - loss: 1.0687 - accuracy: 0.6017 - val_loss: 1.1217 - val_accuracy: 0.5731\n",
      "Epoch 16/50\n",
      "448/448 [==============================] - 219s 488ms/step - loss: 1.0494 - accuracy: 0.6058 - val_loss: 1.1202 - val_accuracy: 0.5738\n",
      "Epoch 17/50\n",
      "448/448 [==============================] - 218s 486ms/step - loss: 1.0234 - accuracy: 0.6213 - val_loss: 1.0998 - val_accuracy: 0.5829\n",
      "Epoch 18/50\n",
      "448/448 [==============================] - 218s 486ms/step - loss: 1.0011 - accuracy: 0.6304 - val_loss: 1.0930 - val_accuracy: 0.5880\n",
      "Epoch 19/50\n",
      "448/448 [==============================] - 226s 505ms/step - loss: 0.9705 - accuracy: 0.6441 - val_loss: 1.0878 - val_accuracy: 0.5963\n",
      "Epoch 20/50\n",
      "448/448 [==============================] - 216s 483ms/step - loss: 0.9502 - accuracy: 0.6498 - val_loss: 1.0893 - val_accuracy: 0.5964\n",
      "Epoch 21/50\n",
      "448/448 [==============================] - 218s 486ms/step - loss: 0.9337 - accuracy: 0.6549 - val_loss: 1.0693 - val_accuracy: 0.5985\n",
      "Epoch 22/50\n",
      "448/448 [==============================] - 218s 486ms/step - loss: 0.9120 - accuracy: 0.6620 - val_loss: 1.0766 - val_accuracy: 0.6016\n",
      "Epoch 23/50\n",
      "448/448 [==============================] - 218s 487ms/step - loss: 0.8861 - accuracy: 0.6746 - val_loss: 1.0679 - val_accuracy: 0.6046\n",
      "Epoch 24/50\n",
      "448/448 [==============================] - 355s 792ms/step - loss: 0.8627 - accuracy: 0.6844 - val_loss: 1.0651 - val_accuracy: 0.6060\n",
      "Epoch 25/50\n",
      "448/448 [==============================] - 427s 953ms/step - loss: 0.8398 - accuracy: 0.6915 - val_loss: 1.0810 - val_accuracy: 0.5988\n",
      "Epoch 26/50\n",
      "448/448 [==============================] - 421s 939ms/step - loss: 0.8154 - accuracy: 0.7041 - val_loss: 1.0649 - val_accuracy: 0.6044\n",
      "Epoch 27/50\n",
      "448/448 [==============================] - 423s 944ms/step - loss: 0.7919 - accuracy: 0.7126 - val_loss: 1.0627 - val_accuracy: 0.6081\n",
      "Epoch 28/50\n",
      "448/448 [==============================] - 426s 951ms/step - loss: 0.7699 - accuracy: 0.7161 - val_loss: 1.0714 - val_accuracy: 0.6059\n",
      "Epoch 29/50\n",
      "448/448 [==============================] - 426s 951ms/step - loss: 0.7464 - accuracy: 0.7276 - val_loss: 1.0686 - val_accuracy: 0.6134\n",
      "Epoch 30/50\n",
      "448/448 [==============================] - 426s 952ms/step - loss: 0.7282 - accuracy: 0.7333 - val_loss: 1.0611 - val_accuracy: 0.6141\n",
      "Epoch 31/50\n",
      "448/448 [==============================] - 422s 942ms/step - loss: 0.7049 - accuracy: 0.7436 - val_loss: 1.0683 - val_accuracy: 0.6133\n",
      "Epoch 32/50\n",
      "448/448 [==============================] - 423s 945ms/step - loss: 0.6837 - accuracy: 0.7502 - val_loss: 1.0672 - val_accuracy: 0.6131\n",
      "Epoch 33/50\n",
      "448/448 [==============================] - 424s 947ms/step - loss: 0.6566 - accuracy: 0.7626 - val_loss: 1.0821 - val_accuracy: 0.6151\n",
      "Epoch 34/50\n",
      "448/448 [==============================] - 339s 757ms/step - loss: 0.6323 - accuracy: 0.7692 - val_loss: 1.0800 - val_accuracy: 0.6169\n",
      "Epoch 35/50\n",
      "448/448 [==============================] - 219s 488ms/step - loss: 0.6191 - accuracy: 0.7756 - val_loss: 1.0855 - val_accuracy: 0.6150\n",
      "Epoch 36/50\n",
      "448/448 [==============================] - 218s 486ms/step - loss: 0.5972 - accuracy: 0.7825 - val_loss: 1.1013 - val_accuracy: 0.6148\n",
      "Epoch 37/50\n",
      "448/448 [==============================] - 219s 488ms/step - loss: 0.5714 - accuracy: 0.7929 - val_loss: 1.1084 - val_accuracy: 0.6140\n",
      "Epoch 38/50\n",
      "448/448 [==============================] - 219s 488ms/step - loss: 0.5612 - accuracy: 0.7955 - val_loss: 1.0940 - val_accuracy: 0.6169\n",
      "Epoch 39/50\n",
      "448/448 [==============================] - 218s 486ms/step - loss: 0.5370 - accuracy: 0.8067 - val_loss: 1.1219 - val_accuracy: 0.6208\n",
      "Epoch 40/50\n",
      "448/448 [==============================] - 219s 488ms/step - loss: 0.5251 - accuracy: 0.8096 - val_loss: 1.1254 - val_accuracy: 0.6136\n",
      "Epoch 41/50\n",
      "448/448 [==============================] - 218s 486ms/step - loss: 0.5038 - accuracy: 0.8186 - val_loss: 1.1125 - val_accuracy: 0.6168\n",
      "Epoch 42/50\n",
      "448/448 [==============================] - 219s 490ms/step - loss: 0.4892 - accuracy: 0.8221 - val_loss: 1.1320 - val_accuracy: 0.6162\n",
      "Epoch 43/50\n",
      "448/448 [==============================] - 217s 485ms/step - loss: 0.4722 - accuracy: 0.8306 - val_loss: 1.1605 - val_accuracy: 0.6117\n",
      "Epoch 44/50\n",
      "448/448 [==============================] - 219s 488ms/step - loss: 0.4549 - accuracy: 0.8348 - val_loss: 1.1485 - val_accuracy: 0.6184\n",
      "Epoch 45/50\n",
      "448/448 [==============================] - 217s 485ms/step - loss: 0.4393 - accuracy: 0.8426 - val_loss: 1.1911 - val_accuracy: 0.6236\n",
      "Epoch 46/50\n",
      "448/448 [==============================] - 218s 486ms/step - loss: 0.4357 - accuracy: 0.8417 - val_loss: 1.1655 - val_accuracy: 0.6214\n",
      "Epoch 47/50\n",
      "448/448 [==============================] - 218s 487ms/step - loss: 0.4146 - accuracy: 0.8504 - val_loss: 1.2007 - val_accuracy: 0.6208\n",
      "Epoch 48/50\n",
      "448/448 [==============================] - 218s 486ms/step - loss: 0.4094 - accuracy: 0.8547 - val_loss: 1.1688 - val_accuracy: 0.6198\n",
      "Epoch 49/50\n",
      "448/448 [==============================] - 217s 485ms/step - loss: 0.3886 - accuracy: 0.8595 - val_loss: 1.1740 - val_accuracy: 0.6229\n",
      "Epoch 50/50\n",
      "448/448 [==============================] - 220s 490ms/step - loss: 0.3807 - accuracy: 0.8638 - val_loss: 1.2053 - val_accuracy: 0.6182\n"
     ]
    }
   ],
   "source": [
    "model_info = model.fit_generator(train_generator, steps_per_epoch=num_train // batch_size,\n",
    "                                 epochs=num_epoch, validation_data=test_generator,\n",
    "                                 validation_steps=num_test // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model.h5')\n",
    "# cv2.ocl.setUseOpenCL(False)\n",
    "emotion_dict = {0: \"Angry\", 1: \"Disgusted\", 2: \"Fearful\", 3: \"Happy\", 4: \"Neutral\", 5: \"Sad\", 6: \"Surprised\"}\n",
    "\n",
    "def rescale_frame(frame, percent=75):\n",
    "    width = int(frame.shape[1] * percent/ 100)\n",
    "    height = int(frame.shape[0] * percent/ 100)\n",
    "    dim = (width, height)\n",
    "    return cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame = rescale_frame(frame, 120)\n",
    "    facecascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = facecascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "    num_of_faces = len(faces)\n",
    "    cnt = 0\n",
    "    nxt = 30\n",
    "    for (x, y, w, h) in faces:\n",
    "        color = (255, 0, 0)  # BGR 0-255\n",
    "        stroke = 2\n",
    "        left_up_cord_x = x\n",
    "        left_up_cord_y = y\n",
    "        right_bottom_cord_x = x + w  # may say width of rectangle\n",
    "        right_bottom_cord_y = y + h  # may say height of rectangle\n",
    "        cv2.rectangle(frame, (left_up_cord_x, left_up_cord_y), (right_bottom_cord_x, right_bottom_cord_y), color, 2)\n",
    "\n",
    "        roi_gray = gray[y:y + h, x:x + w]\n",
    "        cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray, (48, 48)), -1), 0)\n",
    "        prediction = model.predict(cropped_img)\n",
    "        max_index = int(np.argmax(prediction))\n",
    "        \n",
    "        cv2.rectangle(frame, (left_up_cord_x-2, left_up_cord_y-30), (left_up_cord_x+25, left_up_cord_y), color, cv2.FILLED)\n",
    "        cv2.putText(frame, str(cnt), (x+5, y-5), cv2.FONT_HERSHEY_SIMPLEX, .8, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        em_text = \"Face \" + str(cnt) + \": \" + emotion_dict[max_index]\n",
    "        cv2.putText(frame, em_text, (10, 30+nxt), cv2.FONT_HERSHEY_SIMPLEX, .8, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "#         emotion_dict[max_index]\n",
    "        cnt+=1\n",
    "        nxt+=30\n",
    "    text = \"Total faces in frame: \" + str(num_of_faces)\n",
    "    cv2.putText(frame,text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, .8, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    cv2.imshow('Emotion Detection', frame)\n",
    "    cnt = 0\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 7ms/sample - loss: 1.1408 - accuracy: 0.6250\n",
      "accuracy: 62.50%\n"
     ]
    }
   ],
   "source": [
    "(image_batch, label_batch) = test_generator.next()\n",
    "loss, acc = model.evaluate(image_batch, label_batch, verbose=1)\n",
    "print(\"accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
